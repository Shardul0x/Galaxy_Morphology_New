# visualization/export.py
"""
Export utilities for astrophysics data formats
Supports FITS, HDF5, and standard formats
"""

import numpy as np
import pandas as pd
from typing import Optional, Dict, Any, List
import os
from datetime import datetime


class AstrophysicsExporter:
    """
    Export augmented data to standard astrophysics formats
    """
    
    def __init__(self, metadata: Optional[Dict[str, Any]] = None):
        """
        Args:
            metadata: Optional metadata to include in exports
        """
        self.metadata = metadata or {}
        self.metadata['export_date'] = datetime.now().isoformat()
        self.metadata['generator'] = 'AstrophysicsAugmentationPipeline'
    
    def export_to_csv(
        self,
        data: np.ndarray,
        filepath: str,
        column_names: Optional[List[str]] = None,
        include_metadata: bool = True
    ):
        """
        Export data to CSV file
        
        Args:
            data: Data to export [n_samples, n_features]
            filepath: Output file path
            column_names: Optional column names
            include_metadata: Whether to include metadata as comments
        """
        df = pd.DataFrame(data, columns=column_names)
        
        with open(filepath, 'w') as f:
            if include_metadata:
                # Write metadata as comments
                f.write(f"# Generated by {self.metadata['generator']}\n")
                f.write(f"# Export date: {self.metadata['export_date']}\n")
                for key, value in self.metadata.items():
                    if key not in ['generator', 'export_date']:
                        f.write(f"# {key}: {value}\n")
                f.write("#\n")
            
            # Write data
            df.to_csv(f, index=False)
        
        print(f"✓ Exported {len(data)} samples to {filepath}")
    
    def export_to_fits(
        self,
        data: np.ndarray,
        filepath: str,
        column_names: Optional[List[str]] = None,
        column_units: Optional[Dict[str, str]] = None,
        header_cards: Optional[Dict[str, Any]] = None
    ):
        """
        Export data to FITS binary table
        
        Args:
            data: Data to export [n_samples, n_features]
            filepath: Output file path (.fits)
            column_names: Column names
            column_units: Physical units for each column
            header_cards: Additional FITS header cards
        """
        try:
            from astropy.io import fits
            from astropy.table import Table
        except ImportError:
            raise ImportError("astropy required for FITS export. Install with: pip install astropy")
        
        # Create column names if not provided
        if column_names is None:
            column_names = [f'FEATURE_{i}' for i in range(data.shape[1])]
        
        # Create astropy Table
        table = Table(data, names=column_names)
        
        # Add units if provided
        if column_units:
            for col_name, unit in column_units.items():
                if col_name in table.colnames:
                    table[col_name].unit = unit
        
        # Create HDU
        hdu = fits.BinTableHDU(table)
        
        # Add metadata to header
        hdu.header['CREATOR'] = self.metadata['generator']
        hdu.header['DATE'] = self.metadata['export_date']
        
        if header_cards:
            for key, value in header_cards.items():
                hdu.header[key] = value
        
        # Add custom metadata
        for key, value in self.metadata.items():
            if key not in ['generator', 'export_date']:
                try:
                    hdu.header[key.upper()[:8]] = str(value)[:68]
                except:
                    pass
        
        # Write to file
        hdu.writeto(filepath, overwrite=True)
        
        print(f"✓ Exported {len(data)} samples to FITS: {filepath}")
    
    def export_to_hdf5(
        self,
        data: np.ndarray,
        filepath: str,
        dataset_name: str = 'augmented_data',
        column_names: Optional[List[str]] = None,
        compression: str = 'gzip'
    ):
        """
        Export data to HDF5 file
        
        Args:
            data: Data to export [n_samples, n_features]
            filepath: Output file path (.h5 or .hdf5)
            dataset_name: Name of dataset in HDF5 file
            column_names: Column names
            compression: Compression algorithm ('gzip', 'lzf', None)
        """
        import h5py
        
        with h5py.File(filepath, 'w') as f:
            # Create dataset with compression
            dataset = f.create_dataset(
                dataset_name,
                data=data,
                compression=compression
            )
            
            # Add attributes
            dataset.attrs['creator'] = self.metadata['generator']
            dataset.attrs['export_date'] = self.metadata['export_date']
            dataset.attrs['n_samples'] = data.shape[0]
            dataset.attrs['n_features'] = data.shape[1]
            
            if column_names:
                dataset.attrs['column_names'] = column_names
            
            # Add custom metadata
            for key, value in self.metadata.items():
                if key not in ['generator', 'export_date']:
                    try:
                        dataset.attrs[key] = value
                    except:
                        pass
        
        print(f"✓ Exported {len(data)} samples to HDF5: {filepath}")
    
    def export_evolution_sequence(
        self,
        evolution_data: List[np.ndarray],
        time_values: np.ndarray,
        filepath: str,
        format: str = 'hdf5',
        column_names: Optional[List[str]] = None
    ):
        """
        Export temporal evolution sequence
        
        Args:
            evolution_data: List of states [n_timesteps x [n_samples, n_features]]
            time_values: Time values for each state
            filepath: Output file path
            format: Output format ('hdf5', 'npz')
            column_names: Feature names
        """
        if format == 'hdf5':
            import h5py
            
            with h5py.File(filepath, 'w') as f:
                # Create group for evolution data
                evo_group = f.create_group('evolution')
                
                # Store each timestep
                for i, (t, state) in enumerate(zip(time_values, evolution_data)):
                    dataset = evo_group.create_dataset(
                        f'timestep_{i:04d}',
                        data=state,
                        compression='gzip'
                    )
                    dataset.attrs['time'] = t
                
                # Store time values
                f.create_dataset('time_values', data=time_values)
                
                # Add metadata
                f.attrs['n_timesteps'] = len(evolution_data)
                f.attrs['n_samples'] = evolution_data[0].shape[0]
                f.attrs['n_features'] = evolution_data[0].shape[1]
                
                if column_names:
                    f.attrs['column_names'] = column_names
                
                for key, value in self.metadata.items():
                    try:
                        f.attrs[key] = value
                    except:
                        pass
            
            print(f"✓ Exported evolution sequence ({len(evolution_data)} timesteps) to HDF5: {filepath}")
        
        elif format == 'npz':
            # Create dictionary for npz
            save_dict = {
                'time_values': time_values,
                **{f'timestep_{i:04d}': state for i, state in enumerate(evolution_data)}
            }
            
            np.savez_compressed(filepath, **save_dict)
            print(f"✓ Exported evolution sequence ({len(evolution_data)} timesteps) to NPZ: {filepath}")
        
        else:
            raise ValueError(f"Unknown format: {format}")
    
    def export_model_predictions(
        self,
        original: np.ndarray,
        reconstructed: np.ndarray,
        latent: np.ndarray,
        filepath: str,
        column_names: Optional[List[str]] = None
    ):
        """
        Export model predictions with original, reconstructed, and latent representations
        
        Args:
            original: Original data
            reconstructed: Reconstructed data
            latent: Latent representations
            filepath: Output file path (.h5)
            column_names: Feature names
        """
        import h5py
        
        with h5py.File(filepath, 'w') as f:
            # Create datasets
            f.create_dataset('original', data=original, compression='gzip')
            f.create_dataset('reconstructed', data=reconstructed, compression='gzip')
            f.create_dataset('latent', data=latent, compression='gzip')
            
            # Add metadata
            f.attrs['n_samples'] = original.shape[0]
            f.attrs['n_features'] = original.shape[1]
            f.attrs['latent_dim'] = latent.shape[1]
            
            if column_names:
                f.attrs['column_names'] = column_names
            
            for key, value in self.metadata.items():
                try:
                    f.attrs[key] = value
                except:
                    pass
        
        print(f"✓ Exported predictions to HDF5: {filepath}")


class VOTableExporter:
    """
    Export to VOTable format (Virtual Observatory standard)
    Useful for astronomical catalogs
    """
    
    @staticmethod
    def export_to_votable(
        data: np.ndarray,
        filepath: str,
        column_names: List[str],
        column_descriptions: Optional[Dict[str, str]] = None,
        column_units: Optional[Dict[str, str]] = None,
        column_ucds: Optional[Dict[str, str]] = None
    ):
        """
        Export data to VOTable format
        
        Args:
            data: Data to export
            filepath: Output file path (.xml or .vot)
            column_names: Column names
            column_descriptions: Descriptions for each column
            column_units: Physical units
            column_ucds: UCD (Unified Content Descriptors) for each column
        """
        try:
            from astropy.io.votable import from_table, writeto
            from astropy.table import Table
        except ImportError:
            raise ImportError("astropy required for VOTable export")
        
        # Create table
        table = Table(data, names=column_names)
        
        # Add descriptions
        if column_descriptions:
            for col_name, desc in column_descriptions.items():
                if col_name in table.colnames:
                    table[col_name].description = desc
        
        # Add units
        if column_units:
            for col_name, unit in column_units.items():
                if col_name in table.colnames:
                    table[col_name].unit = unit
        
        # Add UCDs
        if column_ucds:
            for col_name, ucd in column_ucds.items():
                if col_name in table.colnames:
                    table[col_name].meta['ucd'] = ucd
        
        # Convert to VOTable and write
        votable = from_table(table)
        writeto(votable, filepath)
        
        print(f"✓ Exported {len(data)} samples to VOTable: {filepath}")
